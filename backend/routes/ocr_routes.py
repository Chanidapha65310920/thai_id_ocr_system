import os
import re
import cv2
import numpy as np
import easyocr
import torch
from flask import Blueprint, request, jsonify
from database import db
from database.models import OcrResult, CerResult
from pathlib import Path
import Levenshtein as L
from utils.normalizer import normalize_pred
from pythainlp.tag import NER
from flask import send_file
import csv
import io

# ====== Thai NER model ======
thai_ner = NER("thainer")

# ====== ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU (MPS) ‡∏ö‡∏ô Mac ======
USE_GPU = torch.backends.mps.is_available()
print(f"üî• EasyOCR is using {'GPU (MPS)' if USE_GPU else 'CPU'}")

# ====== EasyOCR Reader ======
reader = easyocr.Reader(['th'], gpu=USE_GPU)

ocr_bp = Blueprint("ocr_bp", __name__)

# ====== Gaussian Preprocess ======
def preprocess_gaussian(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    return blur

# ====== CER Calculation ======
def compute_cer(pred: str, truth: str) -> float:
    pred = re.sub(r"\s+", "", (pred or "").strip())
    truth = re.sub(r"\s+", "", (truth or "").strip())
    if len(truth) == 0:
        return 0.0 if len(pred) == 0 else 1.0
    return round(L.distance(pred, truth) / len(truth), 4)

# ====== Extract Fields with Regex + NER ======
def extract_fields_from_text(text):
    from pythainlp.tag import NER
    import Levenshtein as L
    import re

    thai_ner = NER("thainer")
    data = {}

    # --- Clean up unwanted chars ---
    text = re.sub(r"[^\u0E00-\u0E7F0-9\s\.\/\-]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()

    # =============================
    # üîπ 1. ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏ö‡∏±‡∏ï‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô
    # =============================
    id_match = re.search(r"\b[1-8]\s?[0-9]{4}\s?[0-9]{5}\s?[0-9]{2}\s?[0-9]\b", text)
    if id_match:
        data["id_number"] = re.sub(r"\s+", "", id_match.group(0))
    else:
        id_match2 = re.search(r"\d{12,}", text)
        data["id_number"] = id_match2.group(0) if id_match2 else ""

    # =============================
    # üîπ 2. ‡πÉ‡∏ä‡πâ NER ‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤ / ‡∏ä‡∏∑‡πà‡∏≠ / ‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏• (‡∏û‡∏£‡πâ‡∏≠‡∏° fallback)
    # =============================
    prefix, first_name, last_name = "", "", ""
    ner_result = thai_ner.tag(text)

    for token, tag in ner_result:
        if tag == "TITLE":
            prefix = token
        elif tag == "NAME" and not first_name:
            first_name = token
        elif tag == "SURNAME" and not last_name:
            last_name = token

    if not prefix or not first_name or not last_name:
        name_match = re.search(
            r"(‡∏ô‡∏≤‡∏¢|‡∏ô‡∏≤‡∏á‡∏™‡∏≤‡∏ß|‡∏ô‡∏≤‡∏á|‡∏ô\.‡∏™\.|‡∏ô‡∏™)\s*([‡∏Å-‡πô]{2,})\s*([‡∏Å-‡πô]{2,})", text
        )
        if name_match:
            prefix = prefix or name_match.group(1)
            first_name = first_name or name_match.group(2)
            last_name = last_name or name_match.group(3)

    data["prefix"] = prefix
    data["first_name"] = first_name
    data["last_name"] = last_name

    # =============================
    # üîπ 3. ‡∏ß‡∏±‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏õ‡∏µ‡πÄ‡∏Å‡∏¥‡∏î
    # =============================
    text_fixed = re.sub(r"‡∏Å\.‡∏∏‡∏û\.", "‡∏Å.‡∏û.", text)
    text_fixed = re.sub(r"‡πÄ‡∏°\.‡∏¢\.", "‡πÄ‡∏°.‡∏¢.", text_fixed)
    dob_match = re.search(
        r"(\d{1,2}\s*(‡∏°\.‡∏Ñ\.|‡∏Å\.‡∏û\.|‡∏°‡∏µ\.‡∏Ñ\.|‡πÄ‡∏°\.‡∏¢\.|‡∏û\.‡∏Ñ\.|‡∏°‡∏¥\.‡∏¢\.|‡∏Å\.‡∏Ñ\.|‡∏™\.‡∏Ñ\.|‡∏Å\.‡∏¢\.|‡∏ï\.‡∏Ñ\.|‡∏û\.‡∏¢\.|‡∏ò\.‡∏Ñ\.)\s*\d{2,4})",
        text_fixed
    )
    data["dob"] = dob_match.group(1) if dob_match else ""

    # =============================
    # üîπ 4. ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡∏°‡πà - ‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå "‡∏ô‡∏±‡∏Å‡∏™‡∏∑‡∏ö‡∏´‡∏≤‡∏ä‡∏¥‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô")
    # =============================
    address = ""
    text_for_addr = re.sub(r"\s+", " ", text) 
    
    # --- Step 1: ‡∏´‡∏≤ Anchor "‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ---
    address_anchor = "‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà"
    best_match_ratio = 0.6
    best_match_start_index = -1

    tokens = text_for_addr.split()
    for token in tokens:
        # ‡πÉ‡∏ä‡πâ Fuzzy matching ‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ "‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà" ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        ratio = L.ratio(token, address_anchor)
        if ratio > best_match_ratio:
            best_match_ratio = ratio
            best_match_start_index = text_for_addr.find(token)
            
    # --- Step 2: ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠ Anchor, ‡∏™‡∏£‡πâ‡∏≤‡∏á "‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤" ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏ä‡∏¥‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô ---
    if best_match_start_index != -1:
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 150 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏´‡∏•‡∏±‡∏á Anchor
        search_window = text_for_addr[best_match_start_index : best_match_start_index + 150]
        
        # --- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á: ‡πÅ‡∏Å‡πâ‡∏Ñ‡∏≥‡∏ú‡∏¥‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠‡∏ö‡πà‡∏≠‡∏¢ ---
        search_window = search_window.replace("‡∏´‡∏°‡πà‡∏ó‡∏µ", "‡∏´‡∏°‡∏π‡πà‡∏ó‡∏µ‡πà").replace("‡∏î.", "‡∏ï.").replace("‡∏ó‡∏ö‡∏Ñ‡∏•‡∏≠", "‡∏ó‡∏±‡∏ö‡∏Ñ‡∏•‡πâ‡∏≠")

        # --- ‡∏ï‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏´‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡∏¥‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Regex ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á ---
        house_no_match = re.search(r"\d+[\/\d-]*", search_window)
        moo_match = re.search(r"(?:‡∏´‡∏°‡∏π‡πà‡∏ó‡∏µ‡πà|‡∏´‡∏°‡∏π‡πà‡∏ó‡∏µ|‡∏´‡∏°‡∏π‡πà|‡∏°\.)\s*\d+", search_window)
        tambon_match = re.search(r"(?:‡∏ï\.?|‡∏ï‡∏≥‡∏ö‡∏•|‡πÅ‡∏Ç‡∏ß‡∏á)\s*[\u0E00-\u0E7F]+", search_window)
        amphoe_match = re.search(r"(?:‡∏≠\.|‡∏≠‡∏≥‡πÄ‡∏†‡∏≠)\s*[\u0E00-\u0E7F]+", search_window)
        province_match = re.search(r"(?:‡∏à\.?|‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î)\s*[\u0E00-\u0E7F]+", search_window)
        
        # --- Step 3: ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏£‡πà‡∏≤‡∏á‡∏ä‡∏¥‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏´‡∏≤‡πÄ‡∏à‡∏≠ ---
        address_parts = []
        if house_no_match:
            address_parts.append(house_no_match.group(0))
        if moo_match:
            address_parts.append(moo_match.group(0))
        if tambon_match:
            address_parts.append(tambon_match.group(0))
        if amphoe_match:
            address_parts.append(amphoe_match.group(0))
        if province_match:
            # ‡∏ô‡∏≥‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏°‡∏≤‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ "‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏à." ‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô‡∏≠‡∏≠‡∏Å
            clean_province = province_match.group(0).replace("‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î", "‡∏à.").strip()
            address_parts.append(clean_province)
            
        # ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏ä‡∏¥‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
        address = " ".join(address_parts)
        address = re.sub(r"\s+", " ", address).strip()

    data["address"] = address

    # =============================
    # üîπ 5. Normalize ‡∏ó‡∏∏‡∏Å‡∏ü‡∏¥‡∏•‡∏î‡πå
    # =============================
    for k in data:
        data[k] = normalize_pred(k, data[k])

    return data

# ====== /upload_ocr ======
# ====== /upload_ocr ======
@ocr_bp.route("/upload_ocr", methods=["POST"])
def upload_ocr():
    file = request.files.get("file")
    user_id = request.form.get("user_id")  # ‚úÖ ‡∏î‡∏∂‡∏á user_id ‡∏à‡∏≤‡∏Å frontend

    # üîπ ‡πÅ‡∏õ‡∏•‡∏á user_id ‡∏à‡∏≤‡∏Å string ‚Üí int
    try:
        user_id = int(user_id) if user_id else None
    except ValueError:
        user_id = None

    # üîπ Debug ‡∏î‡∏π‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà Flask ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö
    print(f"[DEBUG] /upload_ocr: user_id={user_id}, type={type(user_id)}")

    if not file:
        return jsonify({"error": "No file uploaded"}), 400

    ext = os.path.splitext(file.filename)[1].lower()
    if ext not in {".jpg", ".jpeg", ".png"}:
        return jsonify({"error": "File type not allowed"}), 400

    BASE_DIR = Path(__file__).resolve().parents[1]
    save_dir = BASE_DIR / "uploads"
    save_dir.mkdir(exist_ok=True)
    os.chmod(save_dir, 0o777)

    filename = file.filename
    save_path = str(save_dir / filename)
    file.save(save_path)

    # --- ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û + Preprocess ---
    img = cv2.imread(save_path)
    if img is None:
        return jsonify({"error": "Cannot read image"}), 400

    processed = preprocess_gaussian(img)
    processed_path = str(save_dir / f"processed_{filename}")
    cv2.imwrite(processed_path, processed)

    # --- OCR ---
    result = reader.readtext(processed, detail=0, paragraph=True)
    text = "\n".join(result)

    # --- Extract fields ---
    data = extract_fields_from_text(text)

    # ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Draft Record (‡πÄ‡∏Å‡πá‡∏ö OCR ‡∏î‡∏¥‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏Å‡πâ)
    from database.models import OcrResult
    ocr_draft = OcrResult(
        user_id=user_id,
        filename=filename,
        original_image_path=f"uploads/{filename}",
        processed_image_path=f"uploads/processed_{filename}",
        id_number=data.get("id_number"),
        prefix=data.get("prefix"),
        first_name=data.get("first_name"),
        last_name=data.get("last_name"),
        dob=data.get("dob"),
        address=data.get("address"),
        is_draft=bool(True),  # ‚úÖ ‡πÄ‡∏Å‡πá‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÄ‡∏õ‡πá‡∏ô Draft
    )
    db.session.add(ocr_draft)
    db.session.commit()

    return jsonify({
        "message": "OCR (Gaussian + EasyOCR) processed successfully!",
        "filename": filename,
        "raw_text": text,
        "processed_image_path": os.path.join("uploads", f"processed_{filename}"),
        "result": data
    })


# ====== /save_ocr ======
@ocr_bp.route("/save_ocr", methods=["POST"])
def save_ocr():
    data = request.get_json()

    # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
    required = ["filename", "id_number", "prefix", "first_name", "last_name", "dob", "address", "user_id"]
    if not all(k in data for k in required):
        return jsonify({"error": "Missing required fields"}), 400

    filename = data["filename"]
    user_id = data["user_id"]

    # ‚úÖ ‡∏´‡∏≤ draft (‡∏ú‡∏• OCR ‡∏î‡∏¥‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏Å‡πâ) ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏õ‡∏¥‡∏î
    draft = (
        OcrResult.query
        .filter_by(user_id=user_id, filename=filename, is_draft=True)
        .order_by(OcrResult.id.desc())
        .first()
    )

    # ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏´‡∏°‡πà (‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß)
    ocr_result = OcrResult(
        user_id=user_id,
        filename=filename,
        original_image_path=f"uploads/{filename}",
        processed_image_path=f"uploads/processed_{filename}",
        id_number=data["id_number"],
        prefix=data["prefix"],
        first_name=data["first_name"],
        last_name=data["last_name"],
        dob=data["dob"],
        address=data["address"],
        is_draft=False,  # ‚úÖ ‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏•‡∏à‡∏£‡∏¥‡∏á ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà draft
    )
    db.session.add(ocr_result)
    db.session.commit()

    # ‚úÖ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì CER ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö draft (baseline)
    fields = ["id_number", "prefix", "first_name", "last_name", "dob", "address"]
    field_cer = {}

    for f in fields:
        pred = getattr(draft, f) if draft else ""   # baseline = draft
        truth = data.get(f, "")
        field_cer[f] = compute_cer(pred or "", truth or "")

    cer_avg = round(sum(field_cer.values()) / len(field_cer), 4)

    # ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏• CER ‡∏•‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á cer_results
    cer_summary = CerResult(
        ocr_result_id=ocr_result.id,
        filename=filename,
        cer_id_number=field_cer["id_number"],
        cer_prefix=field_cer["prefix"],
        cer_first_name=field_cer["first_name"],
        cer_last_name=field_cer["last_name"],
        cer_dob=field_cer["dob"],
        cer_address=field_cer["address"],
        cer_avg=cer_avg,
    )
    db.session.add(cer_summary)

    # ‚úÖ ‡∏õ‡∏¥‡∏î‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ draft (‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏ã‡πâ‡∏≥)
    # if draft:
    #     draft.is_draft = False

    db.session.commit()

    return jsonify({
        "message": "OCR + CER summary saved successfully!",
        "filename": filename,
        "ocr_result_id": ocr_result.id,
        "cer_avg": cer_avg,
        "fields_cer": field_cer,
        "saved_data": data,
        "processed_image_path": f"uploads/processed_{filename}",
        "original_image_path": f"uploads/{filename}"
    })


# ====== /get_ocr_history ======

@ocr_bp.route("/get_ocr_history/<int:user_id>", methods=["GET"])
def get_ocr_history(user_id):
    """‡∏î‡∏∂‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏ú‡∏• OCR ‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ ‚Äî ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ô (draft ‡∏Å‡πà‡∏≠‡∏ô ‡∏ú‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á)"""
    results = (
        OcrResult.query
        .filter_by(user_id=user_id)
        .order_by(OcrResult.filename.asc(), OcrResult.is_draft.desc(), OcrResult.created_at.asc())
        .all()
    )

    data = []
    for r in results:
        cer = (
            CerResult.query.filter_by(ocr_result_id=r.id)
            .order_by(CerResult.id.desc())
            .first()
        )
        data.append({
            "id": r.id,
            "filename": r.filename,
            "id_number": r.id_number,
            "id_number": r.id_number,
            "prefix": r.prefix,
            "first_name": r.first_name,
            "last_name": r.last_name,
            "dob": r.dob,
            "address": r.address,
            "is_draft": r.is_draft,
            "created_at": r.created_at.strftime("%Y-%m-%d %H:%M"),
            "cer_avg": cer.cer_avg if cer else None
        })

    # ‚úÖ ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ã‡πâ‡∏≥‡πÉ‡∏ô Python ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏ß‡∏£‡πå
    data.sort(key=lambda x: (x["filename"].lower(), 1 if x["is_draft"] else 2))

    return jsonify({"history": data})


@ocr_bp.route("/export_csv_final/<int:user_id>", methods=["GET"])
def export_csv_final(user_id):
    try:
        # ‚úÖ ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß (is_draft = 'Final')
        results = (
            OcrResult.query
            .filter(OcrResult.user_id == user_id, OcrResult.is_draft == "Final")
            .order_by(OcrResult.created_at.desc())
            .all()
        )

        if not results:
            return jsonify({"error": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß"}), 404

        # ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå CSV
        output = io.StringIO()
        writer = csv.writer(output)

        # Header ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
        writer.writerow(["‡πÄ‡∏•‡∏Ç‡∏ö‡∏±‡∏ï‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô", "‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•", "‡∏ß‡∏±‡∏ô‡πÄ‡∏Å‡∏¥‡∏î", "‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà"])

        for r in results:
            full_name = f"{r.prefix or ''}{r.first_name or ''} {r.last_name or ''}".strip()
            writer.writerow([
                r.id_number or "",
                full_name,
                r.dob or "",
                r.address or "",
            ])

        output.seek(0)
        return send_file(
            io.BytesIO(output.getvalue().encode("utf-8-sig")),
            mimetype="text/csv",
            as_attachment=True,
            download_name=f"‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πåOCR_user_{user_id}.csv"
        )

    except Exception as e:
        print("[ERROR /export_csv_final]", e)
        return jsonify({"error": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå CSV ‡πÑ‡∏î‡πâ"}), 500



@ocr_bp.route("/get_cer_details/<int:ocr_id>", methods=["GET"])
def get_cer_details(ocr_id):
    try:
        cer_result = CerResult.query.filter_by(ocr_result_id=ocr_id).first()
        if not cer_result:
            return jsonify({"error": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CER ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ô‡∏µ‡πâ"}), 404

        data = {
    "id_number_cer": cer_result.cer_id_number,
    "prefix_cer": cer_result.cer_prefix,
    "first_name_cer": cer_result.cer_first_name,
    "last_name_cer": cer_result.cer_last_name,
    "dob_cer": cer_result.cer_dob,
    "address_cer": cer_result.cer_address,
    "cer_avg": round(cer_result.cer_avg or 0, 4),
}


        return jsonify(data), 200

    except Exception as e:
        print("[ERROR /get_cer_details]", e)
        return jsonify({"error": "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå"}), 500
